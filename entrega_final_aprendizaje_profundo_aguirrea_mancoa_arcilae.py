# -*- coding: utf-8 -*-
"""ENTREGA FINAL- APRENDIZAJE PROFUNDO_AguirreA_MancoA_ArcilaE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BuFZIUtuLeQl0zSzayptB5C4DgX4pHC6

# APRENDIZAJE PROFUNDO

Integrantes:

**Alejandra Aguirre Monsalve**

**Daniel Alejandro Manco Vidales**

**Faber Esteban Arcila Galvis**

##Descripción del problema

Una empresa de gran tamaño donde se confesionan todo tipo de prendas de vestir enfrenta desafíos significativos en su logística e inventario debido al proceso manual de clasificación. Esta clasificación de las estanterias y productos es realizada con numeración hecha a mano. Este enfoque ha generado errores humanos frecuentes que impactan negativamente la rotación precisa del inventario. El tiempo requerido para la clasificación manual es excesivo, además, está sujeta a la caligrafía y concentración del operario para escribir la referencia de manera correcta y entendible para los demás operarios. Lo que resulta en la mala clasificación y numeración de productos y estanterias. Esta situación ha afectado la eficiencia del jefe de inventario y la problemática se ha intensificado con el tiempo.

Impacto en la empresa:

1. **Errores en la identificación de estanterias y referencias:** Teniendo en cuenta que la numeración es de manera manual, está sujeta a la caligrafía del operario, haciendo que muchos de estos números no sean legibles, generando retrasos en el proceso.
2. **Ineficiencia en el proceso:** El tiempo prolongado requerido para la clasificación manual limita la capacidad de la empresa para responder rápidamente a la demanda del mercado y para mantener un flujo eficiente en la cadena de suministro.
3. **Acumulación de inventario sin clasificar:** La acumulación de inventario no clasificado aumenta el riesgo de pérdida, deterioro o inexactitudes en los registros de inventario.


Debido a que se están generando grandes perdidas la empresa decide invertir en una solución que le permita:

1. **Reconocer patrones numéricos manuales:** A través de una herramienta que permita el reconocimiento correcto de la formas numéricas, hará que se identifiquen los números de manera eficiente, esto con miras a una posible migración a un sistema de gestión de inventario avanzado, sin dejar de lado el sistema de numeración actual.

1. **Precisión en la clasificación:** La automatización del proceso reduciría significativamente los errores humanos, asegurando una clasificación precisa del inventario y una mejor gestión de la rotación de productos.

2. **Ahorro de tiempo:** Al eliminar la necesidad de clasificación manual, se optimizaría el tiempo empleado en esta tarea, permitiendo una gestión más ágil y eficiente del inventario.

3. **Reducción de pérdidas:** La identificación rápida y precisa de productos en mal estado minimizaría las pérdidas por productos no vendidos o desechados.

##Solución Propuesta

**Objetivo**

 Implementar un sistema automatizado de detección de objetos en imágenes para identificar las formas de los números y hacer la migración a un sistema de gestión de inventarios actualizado sin dejar de lado el sistema numérico estandarizado en la empresa, para asi clasificar el inventario de forma precisa y eficiente.

 Con el fin de dar solución al problema de inventarios se utilizarán  conjuntos de datos como MNIST  para desarrollar un modelo capaz de reconocer los números hechos a mano y así actualizar su sistema de inventarios.

**Beneficios:**

1. **Precisión en la clasificación:** La red neuronal ofrecerá una clasificación más precisa en comparación con los métodos manuales, reduciendo drásticamente los errores en la rotación del inventario.

2. **Eficiencia en el proceso:** Al automatizar la clasificación, se reducirá significativamente el tiempo empleado en la tarea manual, permitiendo una gestión más rápida y eficiente del inventario.

4. **Escalabilidad y mejora continua:** El modelo puede adaptarse a nuevos productos y condiciones cambiantes del inventario, mejorando continuamente su precisión con más datos y entrenamiento.

##Exploración y limpieza de datos
"""

pip install keras-tuner

### Carga de paquetes y librerias
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
import numpy as np
import tensorflow as tf #Framework para deep learning
from tensorflow import keras #API que contiene la mayoría de funciones para las RN
from keras_tuner.tuners import RandomSearch
import keras_tuner as kt
from sklearn import metrics

### Carga de datos fasion_mnist
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Se especifica la dimension de las imagenes con el canal (escala de grises)
x_train = x_train.reshape(len(x_train), 28, 28, 1)
x_test = x_test.reshape(len(x_test), 28, 28, 1)
x_train.shape, y_train.shape, x_test.shape, y_test.shape

#Categorias de la variable respuesta
np.unique(y_train,return_counts=True) # vemos que las categorias no estan 100% balanceadas, en la aplicacion de los modelos, mas adelante, veremos si el desbalance es significativo.
np.unique(y_test,return_counts=True)

### Estandarización de los datos
x_train2 = x_train/255 # Valores entre 0 y 1
x_test2 = x_test/255
x_train2.shape

### Definición de la arquitectura para la CNN base
model = keras.models.Sequential()

# Definición de la primera capa convolucional
model.add(
    keras.layers.Conv2D(
        filters = 32, # Cantidad de filtros
        kernel_size = (3,3), # Tamaño de los filtros
        strides = (2,2), # Cantidad de pasos o zancada
        activation = 'relu', # Rectified Linear Unit (ReLU)
        input_shape = (28,28,1) # Tamaño de la imagen
    )
)

# Definición de la capa de agrupación
model.add(
    keras.layers.MaxPooling2D(
        pool_size = (2,2),
        strides = (2,2)
    )
)

### Dimensiones de la imagen
filas_img = 28
columnas_img = 28

# La salida de la capa anterior es un tensor 3D. Se debe conertir a un tensor de 1D
# antes de pasar a las capas densas (Flatten)
model.add(
    keras.layers.Flatten()
)

# Definición de capa totalemente conectada
model.add(
    keras.layers.Dense(
        units = 128,
        activation = 'relu'
    )
)

# Definición de la capa de salida
model.add(
    keras.layers.Dense(
        units= 10,
        activation = 'softmax'
    )
)

# Compilación del modelo
model.compile(
    optimizer = 'adam',
    loss = 'sparse_categorical_crossentropy',
    metrics = ['accuracy']
)

model.summary()

# Representación de la arquitectura
keras.utils.plot_model(
    model,
    to_file = 'model.png',
    show_shapes = True,
    show_layer_names = True
)

### Entrenamiento de la CNN
history = model.fit(
    x_train2,
    y_train,
    epochs = 10,
    validation_split = 0.2
)

### Evaluación del modelo con dataset de test
from sklearn.metrics import classification_report
class_names = ['0','1', '2', '3', '4', '5', '6', '7', '8', '9']

y_hat = np.argmax(model.predict(x_test2), axis = 1)

print(classification_report(y_test, y_hat, target_names=class_names))

### Errores en la red neuronal
errors = np.nonzero(y_hat != y_test)[0]

# Visualizar las primeras 10 predicciones erroneas
plt.figure(figsize=(16, 8))
for i, incorrect in enumerate(errors[0:10]):
    plt.subplot(2,5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(x_test[incorrect].reshape(28,28), cmap = 'Reds')
    plt.title("Prediccion: {}".format(class_names[y_hat[incorrect]]))
    plt.xlabel("Real: {}".format(class_names[y_test[incorrect]]))

"""#Modelo 1"""

### ANN 1: red neuronal base
ann1 = keras.models.Sequential(
    [
        keras.layers.Flatten(input_shape = [filas_img, columnas_img]),
        keras.layers.Dense(128, activation = 'relu'),
        keras.layers.Dense(64, activation = 'relu'),
        keras.layers.Dense(10, activation = 'softmax')
    ]
)

### Compilacion de la ANN1
ann1.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

### Entrenamiento de la ANN1
history = ann1.fit(x_train2, y_train, epochs = 15, validation_data = (x_test2, y_test))

### Listado de toda la data almacenada en 'history'
print(history.history.keys())

### Visualización de las curvas de error
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Perdida del modelo')
plt.xlabel('Tiempo de entrenamiento - Epochs')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

### Visualización de las curvas de error
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Exactitud del modelo')
plt.xlabel('Tiempo de entrenamiento - Epochs')
plt.ylabel('Accuracy')
plt.legend(['train', 'val'])
plt.show()

"""Respecto a la pérdida del modelo, en los datos de entrenamiento disminuye considerablemente de la época 1 a la 15, lo que sugiere que el modelo está mejorando en la tarea que está aprendiendo. Para el caso de la pérdida con los datos de validación también disminuye, aunque puede haber un ligero aumento después de cierto punto (épocas 10-15), lo que podría indicar un posible sobreajuste.

La precisión de entrenamiento aumenta de manera constante, lo que indica que el modelo está aprendiendo bien los datos de entrenamiento. La precisión de validación también aumenta, lo cual es positivo. Sin embargo, a partir de un número de épocas, empieza a disminuir, esto también es muestra de un posible sobreajuste.

#Modelo 2
"""

##### REGULARIZACION #####
from tensorflow.keras import regularizers

### ANN 2: red neuronal regularizada
ann2 = keras.models.Sequential(
    [
        keras.layers.Flatten(input_shape = [filas_img, columnas_img]),
        keras.layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.L2(l2 = 0.01)),
        keras.layers.Dense(64, activation = 'relu'),
        keras.layers.Dense(10, activation = 'softmax')
    ]
)

### Compilacion de la ANN2
ann2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

### Entrenamiento de la ANN2
history_2 = ann2.fit(x_train2, y_train, epochs = 15, validation_data = (x_test2, y_test))

### Visualización de las curvas de error
plt.plot(history_2.history['loss'])
plt.plot(history_2.history['val_loss'])
plt.title('Perdida del modelo')
plt.xlabel('Tiempo de entrenamiento - Epochs')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

### Visualización de las curvas de error
plt.plot(history_2.history['accuracy'])
plt.plot(history_2.history['val_accuracy'])
plt.title('Exactitud del modelo')
plt.xlabel('Tiempo de entrenamiento - Epochs')
plt.ylabel('Accuracy')
plt.legend(['train', 'val'])
plt.show()

"""En este caso, la pérdida en los datos de entrenamiento disminuye de manera constante de la época 1 a la 15, lo que indica que el modelo está aprendiendo los datos de entrenamiento cada vez mejor.
La pérdida de validación disminuye inicialmente, pero desde la época 3 hasta la época 8, hay un comportamiento aleatorio, por último, vuelve a retomar una tendencia a bajar en las últimas épocas.

La precisión de entrenamiento también aumenta, alcanzando alrededor del 96.3% al final del entrenamiento.
La precisión de validación alcanza alrededor del 96.2%, lo cual es bastante cercano a la precisión de entrenamiento.


Este modelo, respecto al modelo 1, es sutilmente inferior respecto a las métricas de pérdida y precisión. Sin embargo, es necesario evaluar los patrones de sobreajuste en ambos modelos, ya que las gráficas muestran que posiblemente la red neuronal esté captando caracteristicas especificas de los datos de entrenamiento.

##Modelo 3
"""

### ANN 3: red neuronal con dropout
ann3 = keras.models.Sequential(
    [
        keras.layers.Flatten(input_shape = [filas_img, columnas_img]),
        keras.layers.Dense(128, activation = 'relu'),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(64, activation = 'relu'),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(10, activation = 'softmax')
    ]
)

### Compilacion de la ANN3
ann3.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

### Entrenamiento de la ANN3
history_3 = ann3.fit(x_train2, y_train, epochs = 15, validation_data = (x_test2, y_test))

### Visualización de las curvas de error
plt.plot(history_3.history['loss'])
plt.plot(history_3.history['val_loss'])
plt.title('Perdida del modelo')
plt.xlabel('Tiempo de entrenamiento - Epochs')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

### Visualización de las curvas de error
plt.plot(history_3.history['accuracy'])
plt.plot(history_3.history['val_accuracy'])
plt.title('Exactitud del modelo')
plt.xlabel('Tiempo de entrenamiento - Epochs')
plt.ylabel('Accuracy')
plt.legend(['train', 'val'])
plt.show()

"""La pérdida de entrenamiento disminuye constantemente de la época 1 a la 15, indicando que el modelo está aprendiendo bien los datos de entrenamiento.
La pérdida de validación también disminuye durante las épocas, aunque hay un ligero aumento hacia el final.

La precisión de entrenamiento aumenta y alcanza un nivel alto del 98.39% al final del entrenamiento.
La precisión de validación alcanza un nivel elevado del 98.06%

Para realizar un análisis general de los 3 modelos se concluye con las siguientes consideraciones:

El primer modelo sigue siendo el mejor en términos de precisión de
entrenamiento, pero el tercer modelo tiene una precisión de validación más alta, lo que sugiere una mejor capacidad de generalización.

El segundo modelo tiene un rendimiento ligeramente inferior tanto en precisión de entrenamiento como de validación en comparación con los otros dos modelos.

##Ajuste de redes neuronales
"""

### Definición del Hyper model
def build_model(hp):
    model = keras.Sequential()
    model.add(keras.layers.Flatten(input_shape=(28,28)))

    # Defenición de la primera capa oculta con ajuste de hiperparámetros
    # Elegir el valor óptimo entre 32 - 512 neuronas
    hp_units_1 = hp.Int('units_1', min_value=32, max_value=512, step=32)
    model.add(keras.layers.Dense(units=hp_units_1, activation='relu'))

    # Defenición de la segunda capa oculta con ajuste de hiperparámetros
    # Elegir el valor óptimo entre 32 - 512 neuronas
    hp_units_2 = hp.Int('units_2', min_value=32, max_value=512, step=32)
    model.add(keras.layers.Dense(units=hp_units_2, activation='relu'))

    # Definición de la capa de salida
    model.add(keras.layers.Dense(10, activation='softmax'))

    # Definición de la tasa de aprendizaje del optimizador
    # Elegir el valor óptimos entre 0.1, 0.01, 0.001, 0.0001
    hp_learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01, 0.001, 0.0001])
    model.compile(
        optimizer = keras.optimizers.Adam(learning_rate= hp_learning_rate),
        loss = 'sparse_categorical_crossentropy',
        metrics = ['accuracy']
    )

    return model

### Definción del tuner
tuner = RandomSearch(
    build_model,
    objective= 'val_accuracy',
    max_trials=5,
    executions_per_trial= 3,
    directory = 'results_tuner',
    project_name = 'fashion_mnist'

)

### Ejecución del Tuner
tuner.search(x_train2, y_train, epochs=5, validation_data= (x_test2, y_test))

### Mostrar el mejor modelo
for h_param in [f"units_{i}" for i in range(1,3)] + ['learning_rate']:
                print(h_param, tuner.get_best_hyperparameters()[0].get(h_param))

### Almacenar el mejor modelo
best_model = tuner.get_best_models()[0]
### Definir la arquitectura del modelo según hiperparámetros optimos
best_model.build(x_train2.shape)
### Resumen de la arquitectura
best_model.summary()

### Ajuste de la red neuronal con hiperparámetros optimos
history = best_model.fit(x_train2, y_train, epochs=10, validation_data = (x_test2, y_test))

### Cual es el epoch con max val_accuracy
val_accuracy_per_epoch = history.history['val_accuracy']
best_epoch = val_accuracy_per_epoch.index(max(val_accuracy_per_epoch))+1
print(f"Best epoch: {best_epoch}")

### Visualización de las curvas de error
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Perdida del modelo')
plt.xlabel('Tiempo de entrenamiento - Epochs')
plt.ylabel('Loss')
plt.legend(['train', 'val'])
plt.show()

### Visualización de las curvas de error
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Exactitud del modelo')
plt.xlabel('Tiempo de entrenamiento - Epochs')
plt.ylabel('Accuracy')
plt.legend(['train', 'val'])
plt.show()

### Utilizar el metodo evaluate para evaluar la red neuronal
test_loss, test_accuracy = best_model.evaluate(x_test2, y_test)
print('Test accuracy: ', test_accuracy)

#Resumen de todas las corridas realizadas con el proceso de afinamiento de hiperparametros
tuner.results_summary() #resumen de las corridas
#este metodo no mejora signficativametelas mertricas de desempeñ o de modelo

#Metricas de desempeño del mejor modelo encontrado

ann_winner=tuner.get_best_models(num_models=3)[0] #obtener los dos mejores modelos y de ellos el primero(0)

pred=np.argmax(ann_winner.predict(x_test2), axis=1) #prediccion sobre x_test2 usando el modelo ganador

print(metrics.classification_report(y_test,pred))

"""Este modelo con afinamiento de hiperparametros, supera a los modelos anteriores tanto en precisión de entrenamiento como de validación.

En términos de precisión de validación, este modelo muestra un rendimiento superior.

##Ajustar modelo de Shallow Learnig
"""

n_obs_tr=x_train.shape[0] #numero de observaciones de train
n_obs_te=x_test.shape[0] #numero de observaciones de test
fxc = filas_img*columnas_img

#reshape
x_train_rf=x_train2.reshape(n_obs_tr,fxc) #se realiza re_shape para dejar vectores que pueda usar el algoritmo de rf
x_test_rf=x_test2.reshape(n_obs_te,fxc)

###ajustar modelo
rf1=RandomForestClassifier(max_depth = 7)
rf1.fit(x_train_rf,y_train)# ajustar o entrenar a datos
##analizar desempeño de el modelo random forest
pred_tr=rf1.predict(x_train_rf)  ###predicciones en entrenamiento
pred_te=rf1.predict(x_test_rf)   ##predicciones en evaluacion
print( metrics.classification_report(y_train,pred_tr))
print( metrics.classification_report(y_test,pred_te))

"""En este caso, encontramos una precisión del 92%, pero para este caso, es necesario analizar los valores verdaderos y los de predicción, para este haremos matrices de confusión para los datos de entrenamiento y validación."""

###matriz de confusion
cm_tr=metrics.confusion_matrix(y_train,pred_tr)###para crear matriz de confusion de entrenamiento
cm_te=metrics.confusion_matrix(y_test,pred_te)###para crear matriz de confusion de test
###graficar matriz de confusion train
disp_tr=metrics.ConfusionMatrixDisplay(cm_tr)
disp_tr.plot()
###graficar matriz de confusion test
disp_te=metrics.ConfusionMatrixDisplay(cm_te)
disp_te.plot()

"""Al realizar el análisis de la matriz de confusión, en ambos conjuntos de datos (Entrenamiento y Validación), se observa que los valores con menos verdaderos positivos detectados son el 4, 5 y 8. Esto posiblemente se da, porque el 4 tiene un patrón de escritura similar al 9, esto mismo pasa entre el 5 y el 3, también con el 8 y el 3. Esto, podria ser la causa por la cual no se llega a una identificación certeza en todos los tipos de datos, reduciendo la capacidad de los modelos.

## Conclusiones

1. Las métricas de precisión, recall y F1-score son bastante altas en todas las clases. Esto sugiere que el modelo es capaz de distinguir y clasificar con precisión la mayoría de las clases.

2. En general, la precisión y la recall son altas y están cercanas entre sí para la mayoría de las clases. Esto indica que el modelo no solo está prediciendo con precisión, sino que también está recuperando la mayoría de las instancias relevantes para cada clase.

3. Las métricas son consistentes en todas las clases, lo que sugiere que el modelo no está sesgado hacia ninguna clase específica y funciona bien en todas ellas.

4. La precisión global del modelo en el conjunto de datos de prueba es alta (98%). Esto sugiere que el modelo generaliza bien y tiene un buen rendimiento en datos que no ha visto durante el entrenamiento.

5. La precisión del modelo permite reconocer y clasificar correctamente los números manuales. Esta métrica es crucial, ya que determinará la confiabilidad del sistema en la identificación de referencias y estanterías.

6. Es importante comparar el rendimiento del modelo con el proceso manual actual para determinar la reducción de errores. Si el modelo logra minimizar significativamente los errores en la identificación y clasificación, se habrá alcanzado uno de los objetivos clave.

7. Se debe tener en cuenta que factores como la caligrafia y el patrón de escritura de los números jugan un papel relevante en la identificación correcta por parte del modelode redes neuronales, ya que puede llevar a esta a una mala identificación de los números, como se evidenció en las matrices de confusión.
"""